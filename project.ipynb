{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "import numpy as np\n",
    "from neuralNetwork import NeuralNetwork, In_between_epochs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from random import shuffle, randint\n",
    "from transformers import RobertaModel, RobertaTokenizer, AutoTokenizer, AutoModel\n",
    "from helper import dict_lists_to_list_of_dicts, get_train_valdiation_test_split, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ECHR_Corpus.json\")\n",
    "dataset = load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "ogni caso nel dataset è organizzato così:\n",
    "```json\n",
    "{\n",
    "    \"text\":\"il testo completo della sentenza\"\n",
    "    \"clauses\":[\n",
    "        {\n",
    "            \"_id\": \"id della clause\",\n",
    "            \"start\": \"index di inizio della clause\",\n",
    "            \"end\": \"index di fine della cluause\"\n",
    "        },\n",
    "        {\n",
    "            \"...\":\"...\"\n",
    "        }\n",
    "    ]\n",
    "    \"argument\":[\n",
    "        {\n",
    "            \"premises\":[\n",
    "                \"id premise1\", \"id premise2\", \"...\"\n",
    "            ],\n",
    "            \"conclusion\": \"id conclusion\"\n",
    "        },\n",
    "        {\n",
    "            \"...\":\"...\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "In questo passaggio riorganizzo i dati per avere comunque la stessa struttura ma trasformo le clauses in un dizionario che ha come id la chiave della clause e come valore il testo (senza quindi dover usare start e end per cercarlo nel testo). Non tutte le clause sono parte di una premessa o di una conclusione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "refactored_dataset = []\n",
    "for datapoint in dataset:\n",
    "    text = datapoint[\"text\"]\n",
    "    dict_clauses = {}\n",
    "    for clause in datapoint[\"clauses\"]:\n",
    "        start = clause[\"start\"]\n",
    "        end = clause[\"end\"]\n",
    "        id = clause[\"_id\"]\n",
    "        dict_clauses[id] = text[start:end]\n",
    "    refactored_dataset.append({\n",
    "        \"text\": text,\n",
    "        \"arguments\": datapoint[\"arguments\"],\n",
    "        \"n_clauses\": len(datapoint[\"clauses\"]),\n",
    "        \"all_clauses\": dict_clauses\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondo me ha poco senso salvare il dataset come dataframe dato che è praticamente solo testo. Comunque non dovrebbe essere difficilissimo tirarci fuori qualche statistica. Ho fatto degli esempi scemi qua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On average, a case has 248.95 clauses with a median of 226 clauses per case.\n",
      "On average, a case has 17.69 arguments with a median of 14 arguments per case.\n",
      "Each argument, on average, has: 2.63 premises with a median of 2 premises per argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_arguments = []\n",
    "n_premises = []\n",
    "n_clauses = []\n",
    "for case in refactored_dataset:\n",
    "    n_arguments.append(len(case[\"arguments\"]))\n",
    "    n_clauses.append(case[\"n_clauses\"])\n",
    "    for argument in case[\"arguments\"]:\n",
    "        n_premises.append(len(argument[\"premises\"]))\n",
    "print(f\"\"\"\n",
    "On average, a case has {np.mean(n_clauses):.2f} clauses with a median of {np.median(n_clauses):.0f} clauses per case.\n",
    "On average, a case has {np.mean(n_arguments):.2f} arguments with a median of {np.median(n_arguments):.0f} arguments per case.\n",
    "Each argument, on average, has: {np.mean(n_premises):.2f} premises with a median of {np.median(n_premises):.0f} premises per argument.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qua puoi vedere come tirare fuori il testo di una conclusion o di una premise: ti basta usare la conclusion/premise come indice nel dizionario delle clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here an example of an argument:\n",
      "    - Premises:\n",
      "        The Commission notes that the applicant was detained after having been sentenced by the first instance court to 18 months' imprisonment.\n",
      "\tHe was released after the Court of Appeal reviewed this sentence, reducing it to 15 months' imprisonment, convertible to a fine.\n",
      "    - Conclusion:\n",
      "        The Commission finds that the applicant was deprived of his liberty \"after conviction by a competent court\" within the meaning of Article 5 para. 1 (a) (Art. 5-1-a) of the Convention.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premise = \"\\n\\t\".join([refactored_dataset[0][\"all_clauses\"][premise] for premise in refactored_dataset[0][\"arguments\"][0][\"premises\"]])\n",
    "conclusion = refactored_dataset[0][\"all_clauses\"][refactored_dataset[0][\"arguments\"][0][\"conclusion\"]]\n",
    "print(f\"\"\"\n",
    "Here an example of an argument:\n",
    "    - Premises:\n",
    "        {premise}\n",
    "    - Conclusion:\n",
    "        {conclusion}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Argument Clause Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9, 4, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases, validation_cases, test_cases = get_train_valdiation_test_split(refactored_dataset, [9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 35 cases in the training set, \n",
      "3 cases in the validation set and\n",
      "4 cases in the test set\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"there are {len(train_cases)} cases in the training set, \n",
    "{len(validation_cases)} cases in the validation set and\n",
    "{len(test_cases)} cases in the test set\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dato che non tutte le clause sono parte di una premise/conclusion, le dividiamo per cercare di tirare fuori un classificatore di clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:\n",
      "\n",
      "There are:\n",
      "      - 3351 clause\n",
      "      - 1953 true clause\n",
      "      - 1398 fake clause\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set:\n",
      "\n",
      "There are:\n",
      "      - 541 clause\n",
      "      - 284 true clause\n",
      "      - 257 fake clause\n",
      "\n",
      "test set:\n",
      "\n",
      "There are:\n",
      "      - 798 clause\n",
      "      - 457 true clause\n",
      "      - 341 fake clause\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_acr_dataloader(cases, tokenizer, batch_size=16, shuffle=False, verbose=True):\n",
    "    ACR_x = []\n",
    "    ACR_y = []\n",
    "    for case in cases:\n",
    "        n_clauses = case[\"n_clauses\"]\n",
    "        clauses = case[\"all_clauses\"]\n",
    "        args_set = set()\n",
    "        splitter = \"AS TO THE LAW\" if \"AS TO THE LAW\" in case[\"text\"] else \"THE LAW\"\n",
    "        law_section = case[\"text\"].split(splitter)[1]\n",
    "        for argument in case[\"arguments\"]:\n",
    "            ACR_x.append(clauses[argument[\"conclusion\"]])\n",
    "            ACR_y.append(torch.tensor([1,0]))\n",
    "            args_set.add(argument[\"conclusion\"])\n",
    "            for premise in argument[\"premises\"]:\n",
    "                ACR_x.append(clauses[premise])\n",
    "                ACR_y.append(torch.tensor([1.,0]))\n",
    "                args_set.add(premise)\n",
    "        for clause_id in clauses.keys():\n",
    "            if not clause_id in args_set and clauses[clause_id] in law_section:\n",
    "                ACR_x.append(clauses[clause_id])\n",
    "                ACR_y.append(torch.tensor([0,1.]))\n",
    "    print(f\"\"\"\n",
    "There are:\n",
    "      - {len(ACR_x)} clause\n",
    "      - {len([a for a in ACR_y if a[0] == 1])} true clause\n",
    "      - {len([a for a in ACR_y if a[0] == 0])} fake clause\n",
    "\"\"\")\n",
    "    ACR_x_tokenized = dict_lists_to_list_of_dicts(tokenizer(ACR_x, padding=True, truncation=True, return_tensors='pt'))\n",
    "    dataset = Dataset(ACR_x_tokenized, ACR_y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "print(\"train set:\")\n",
    "train_dataloader = get_acr_dataloader(train_cases, tokenizer, shuffle=True, batch_size=8)\n",
    "print(\"validation set:\")\n",
    "validation_dataloder = get_acr_dataloader(validation_cases, tokenizer, batch_size=8)\n",
    "print(\"test set:\")\n",
    "test_dataloader = get_acr_dataloader(test_cases, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_text_file(dataset):\n",
    "#     text = \"\"\n",
    "#     for case in dataset:\n",
    "#         text += \"\\n\\n\" + case[\"text\"]\n",
    "\n",
    "#     f = open(\"pre_train_text.txt\", \"w\")\n",
    "#     f.write(text)\n",
    "\n",
    "# to_text_file(refactored_dataset[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertForMaskedLM\n",
    "# from transformers import LineByLineTextDataset, DataCollatorForLanguageModeling\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# train_data_file = \"pre_train_text.txt\"\n",
    "\n",
    "# train_dataset = LineByLineTextDataset(\n",
    "#     tokenizer=tokenizer,\n",
    "#     file_path=train_data_file,\n",
    "#     block_size=128,\n",
    "# )\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "# )\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     overwrite_output_dir=True,\n",
    "#     num_train_epochs=8,  \n",
    "#     per_device_train_batch_size=16,\n",
    "#     save_steps=10_000,  \n",
    "#     save_total_limit=2, \n",
    "#     prediction_loss_only=True,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     data_collator=data_collator,\n",
    "#     train_dataset=train_dataset,\n",
    "# )\n",
    "\n",
    "# # Start pre-training\n",
    "# trainer.train()\n",
    "# trainer.save_model(\"./bert_pretrained/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Da qui in avanti ti dovrebbe essere tutto abbastanza familiare dato che è praticamente lo stesso codice dell'assignment 2. Qua ho fatto solo 5 epoche e con un learning rate a caso ma è giusto per far vedere come funziona. Da ora si può iniziare a giocare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = .3) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _, encoded_input = self.encoder(**input, return_dict = False)\n",
    "        encoded_input = self.dropout(encoded_input)\n",
    "    \n",
    "        return self.output_layer(encoded_input)\n",
    "    \n",
    "model = Model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"operating on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(In_between_epochs):\n",
    "    def __init__(self, delta, patience):\n",
    "        self.delta = delta\n",
    "        self.patience = patience\n",
    "        self.current_patience = 0\n",
    "        self.best_valid_loss = 100000000000000000000\n",
    "        self.best_model = None\n",
    "        self.epochs = 0\n",
    "    \n",
    "    def __call__(self, model:torch.nn.Module, loaders:dict[str,torch.utils.data.DataLoader], device:'torch.device|str', output_extraction_function, losses:dict[str, float]) -> bool:\n",
    "        self.epochs += 1\n",
    "        if losses[\"train\"] < self.best_valid_loss - self.delta:\n",
    "            self.best_valid_loss = losses[\"train\"]\n",
    "            self.best_model = model\n",
    "            self.current_patience = 0\n",
    "        else:\n",
    "            self.current_patience += 1\n",
    "            if self.current_patience >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "    def reset(self):\n",
    "        self.current_patience = 0\n",
    "        self.epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train, validation, min_lr, start_lr, early_stopping, frac):\n",
    "    tot_train_data, tot_val_data = [], []\n",
    "    lr = start_lr\n",
    "    while lr > min_lr:\n",
    "        train_data, validation_data = model.train_network(train, \n",
    "                        validation, \n",
    "                        torch.optim.SGD, \n",
    "                        loss_function=nn.CrossEntropyLoss(),\n",
    "                        device=device, \n",
    "                        batch_size=32,\n",
    "                        verbose=True, \n",
    "                        output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                        metrics={\n",
    "                        \"accuracy\": accuracy_score, \n",
    "                        \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                        in_between_epochs = {\"early_stopping\": early_stopping},\n",
    "                        learning_rate=lr,\n",
    "                        epochs=30)\n",
    "        train_data[\"epochs\"] = early_stopping.epochs\n",
    "        train_data[\"lr\"] = lr\n",
    "        validation_data[\"epochs\"] = early_stopping.epochs\n",
    "        validation_data[\"lr\"] = lr\n",
    "        tot_train_data.append(train_data)\n",
    "        tot_val_data.append(validation_data)\n",
    "        model = early_stopping.best_model\n",
    "        lr = lr * frac\n",
    "        early_stopping.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.667 - validation loss:      0.706                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.609 - validation accuracy:      0.538\n",
      "EPOCH 1 training f1_score:      0.454 - validation f1_score:      0.447\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.656 - validation loss:      0.710                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.613 - validation accuracy:      0.542\n",
      "EPOCH 2 training f1_score:      0.463 - validation f1_score:      0.471\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.630 - validation loss:      0.711                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.655 - validation accuracy:      0.569\n",
      "EPOCH 3 training f1_score:      0.525 - validation f1_score:      0.497\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.602 - validation loss:      0.692                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.702 - validation accuracy:      0.549\n",
      "EPOCH 4 training f1_score:      0.626 - validation f1_score:      0.435\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "stopping after 4 epochs because of in between early_stopping\n",
      "EPOCH 1 training loss:      0.579 - validation loss:      0.726                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.709 - validation accuracy:      0.573\n",
      "EPOCH 1 training f1_score:      0.634 - validation f1_score:      0.468\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.563 - validation loss:      0.717                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.723 - validation accuracy:      0.578\n",
      "EPOCH 2 training f1_score:      0.653 - validation f1_score:      0.495\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.547 - validation loss:      0.742                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.734 - validation accuracy:      0.578\n",
      "EPOCH 3 training f1_score:      0.662 - validation f1_score:      0.470\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.531 - validation loss:      0.733                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.743 - validation accuracy:      0.571\n",
      "EPOCH 4 training f1_score:      0.689 - validation f1_score:      0.431\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "stopping after 4 epochs because of in between early_stopping\n",
      "EPOCH 1 training loss:      0.526 - validation loss:      0.746                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.747 - validation accuracy:      0.588\n",
      "EPOCH 1 training f1_score:      0.691 - validation f1_score:      0.443\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.515 - validation loss:      0.737                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.755 - validation accuracy:      0.579\n",
      "EPOCH 2 training f1_score:      0.708 - validation f1_score:      0.428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.507 - validation loss:      0.738                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.758 - validation accuracy:      0.584\n",
      "EPOCH 3 training f1_score:      0.698 - validation f1_score:      0.439\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "stopping after 3 epochs because of in between early_stopping\n",
      "EPOCH 1 training loss:      0.503 - validation loss:      0.738                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.764 - validation accuracy:      0.587\n",
      "EPOCH 1 training f1_score:      0.713 - validation f1_score:      0.428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.499 - validation loss:      0.714                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.768 - validation accuracy:      0.581\n",
      "EPOCH 2 training f1_score:      0.730 - validation f1_score:      0.435\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "batch 29/418 ----- loss:      0.312 ----- accuracy:      0.750 ----- f1_score:      0.691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\u001b[38;5;241m.08\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train, validation, min_lr, start_lr, early_stopping, frac)\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m start_lr\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m lr \u001b[38;5;241m>\u001b[39m min_lr:\n\u001b[0;32m----> 5\u001b[0m     train_data, validation_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moutput_extraction_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1_score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43min_between_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mearly_stopping\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m early_stopping\u001b[38;5;241m.\u001b[39mepochs\n\u001b[1;32m     20\u001b[0m     train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n",
      "File \u001b[0;32m~/Documents/University/projects/NLP_project/neuralNetwork.py:88\u001b[0m, in \u001b[0;36mNeuralNetwork.train_network\u001b[0;34m(self, train_loader, validation_loader, optimizer, loss_function, learning_rate, epochs, batch_size, device, output_extraction_function, metrics, in_between_epochs, verbose, automatically_handle_gpu_memory)\u001b[0m\n\u001b[1;32m     86\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 88\u001b[0m predicted_classes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43moutput_extraction_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m normal_labels \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m output_extraction_function(labels)\n\u001b[1;32m     90\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch_idx \u001b[38;5;241m*\u001b[39m train_loader\u001b[38;5;241m.\u001b[39mbatch_size\n",
      "Cell \u001b[0;32mIn[17], line 12\u001b[0m, in \u001b[0;36mtrain.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m start_lr\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m lr \u001b[38;5;241m>\u001b[39m min_lr:\n\u001b[1;32m      5\u001b[0m     train_data, validation_data \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_network(train, \n\u001b[1;32m      6\u001b[0m                     validation, \n\u001b[1;32m      7\u001b[0m                     torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD, \n\u001b[1;32m      8\u001b[0m                     loss_function\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[1;32m      9\u001b[0m                     device\u001b[38;5;241m=\u001b[39mdevice, \n\u001b[1;32m     10\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     11\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m---> 12\u001b[0m                     output_extraction_function\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m     13\u001b[0m                     metrics\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     14\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: accuracy_score, \n\u001b[1;32m     15\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: f1_score(y_true, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)},\n\u001b[1;32m     16\u001b[0m                     in_between_epochs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping\u001b[39m\u001b[38;5;124m\"\u001b[39m: early_stopping},\n\u001b[1;32m     17\u001b[0m                     learning_rate\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     18\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m     19\u001b[0m     train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m early_stopping\u001b[38;5;241m.\u001b[39mepochs\n\u001b[1;32m     20\u001b[0m     train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m lr\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(.08, 3)\n",
    "train(model, train_dataloader, validation_dataloder, 1e-7, 1e-4, early_stopping, .6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.685 - validation loss:      0.697                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.583 - validation accuracy:      0.571\n",
      "EPOCH 1 training f1_score:      0.366 - validation f1_score:      0.563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.681 - validation loss:      0.691                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.583 - validation accuracy:      0.571\n",
      "EPOCH 2 training f1_score:      0.369 - validation f1_score:      0.563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.681 - validation loss:      0.690                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.583 - validation accuracy:      0.571\n",
      "EPOCH 3 training f1_score:      0.368 - validation f1_score:      0.563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.681 - validation loss:      0.690                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.583 - validation accuracy:      0.571\n",
      "EPOCH 4 training f1_score:      0.368 - validation f1_score:      0.563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 training loss:      0.684 - validation loss:      0.695                                                                                                                                                                                                                                                      \n",
      "EPOCH 5 training accuracy:      0.583 - validation accuracy:      0.571\n",
      "EPOCH 5 training f1_score:      0.370 - validation f1_score:      0.563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data =   model.train_network(train_dataloader, \n",
    "                    test_dataloader, \n",
    "                    torch.optim.Adam, \n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    device=device, \n",
    "                    batch_size=32,\n",
    "                    verbose=True, \n",
    "                    output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                    metrics={\n",
    "                     \"accuracy\": accuracy_score, \n",
    "                     \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                    learning_rate=1e-5,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Argument Relation Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_premises(idx_1, argument):\n",
    "    idx_2 = randint(0, len(argument[\"premises\"]) - 1)\n",
    "    while idx_1 == idx_2:\n",
    "       idx_2 = randint(0, len(argument[\"premises\"]) - 1)\n",
    "    premise_1 = argument[\"premises\"][idx_1]\n",
    "    premise_2 = argument[\"premises\"][idx_2]\n",
    "    return {\n",
    "        \"e1\": clauses[premise_1],\n",
    "        \"e2\": clauses[premise_2]\n",
    "    }, (premise_1, premise_2)\n",
    "\n",
    "def add_premise_conclusion(idx_1, argument):\n",
    "    premise = argument[\"premises\"][idx_1]\n",
    "    conclusion = argument[\"conclusion\"]\n",
    "    if randint(1, 10) > 5: # with 50% chance we make the premise the first element\n",
    "        return {\n",
    "            \"e1\": clauses[premise],\n",
    "            \"e2\": clauses[conclusion]\n",
    "        }, (premise, conclusion)\n",
    "    else: # with 50% chance we make the conclusion the first element\n",
    "        return {\n",
    "            \"e2\": clauses[conclusion],\n",
    "            \"e1\": clauses[premise]\n",
    "        }, (premise, conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are:\n",
      "      - 3194 couples\n",
      "      - 1597 related clauses:\n",
      "        - 777 are couple of clauses both premises on the same argument\n",
      "        - 820 are couple of clauses premise and conclusion on the same argument\n",
      "      - 1597 unrelated clauses:\n",
      "        - 485 are couple with two premises from different arguments\n",
      "        - 488 are couple with a premise and a conclusion from two different arguments\n",
      "        - 624 are couple with two conclusions from different arguments\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ARM_x = []\n",
    "# ARM_y = []\n",
    "# FACTOR = .6\n",
    "# n_related_two_premises = 0\n",
    "# n_related_premise_conclusion = 0\n",
    "# n_unrelated_two_premises = 0\n",
    "# n_unrelated_two_conclusions = 0\n",
    "# n_unrelated_premise_conclusion = 0\n",
    "# for case in refactored_dataset: # for each case\n",
    "#     n_clauses = case[\"n_clauses\"]\n",
    "#     clauses = case[\"all_clauses\"]\n",
    "\n",
    "#     args_set = set() # get the number of clauses in arguments\n",
    "#     for argument in case[\"arguments\"]: \n",
    "#         args_set.add(argument[\"conclusion\"])\n",
    "#         for premise in argument[\"premises\"]:\n",
    "#             args_set.add(premise)\n",
    "\n",
    "#     n_related = int(len(args_set) * FACTOR) # get the number of elements we want from a given case \n",
    "#     n_unrelated = int(len(args_set) * FACTOR)\n",
    "#     already_taken_couples = set()\n",
    "#     related = []\n",
    "#     unrelated = []\n",
    "#     while len(related) < n_related: # generate untill we need more related elements \n",
    "#         while True:\n",
    "#             idx_argument = randint(0, len(case[\"arguments\"]) - 1) # take a random argument\n",
    "#             argument = case[\"arguments\"][idx_argument]\n",
    "#             idx_1 = randint(0, len(argument[\"premises\"]) - 1) #take a random premise (we know we need at least 1 premise since there is only 1 conclusion)\n",
    "#             if len(argument[\"premises\"]) > 1: # some arguments have only 1 premise\n",
    "#                 two_premises = randint(0,10)\n",
    "#                 if two_premises >= 4: # with 60% chance we get 2 random premises\n",
    "#                     element, (id_1, id_2) = add_two_premises(idx_1, argument)\n",
    "#                     if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples): #we add them only if we do not already have selected the combination\n",
    "#                         related.append(element)\n",
    "#                         n_related_two_premises += 1\n",
    "#                         already_taken_couples.add(id_1 + id_2)\n",
    "#                         break\n",
    "#                 else: #with 40% chance we get a premise and a conclusion\n",
    "#                     element, (id_1, id_2) = add_premise_conclusion(idx_1, argument)\n",
    "#                     if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples): #only if the couple has not been already selected\n",
    "#                         related.append(element)\n",
    "#                         n_related_premise_conclusion += 1\n",
    "#                         already_taken_couples.add(id_1 + id_2)\n",
    "#                         break\n",
    "#             else: # if we have only one premise we just get the premise and conclusion\n",
    "#                 element, (id_1, id_2) = add_premise_conclusion(idx_1, argument)\n",
    "#                 if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples):\n",
    "#                     related.append(element)\n",
    "#                     n_related_premise_conclusion += 1\n",
    "#                     already_taken_couples.add(id_1 + id_2)\n",
    "#                     break\n",
    "\n",
    "#     while len(unrelated) < n_unrelated: # generate untill we need more unrelated elements \n",
    "#         while True:\n",
    "#             idx_argument_1 = randint(0, len(case[\"arguments\"]) - 1) # select 2 random arguments \n",
    "#             idx_argument_2 = randint(0, len(case[\"arguments\"]) - 1)\n",
    "#             while idx_argument_1 == idx_argument_2: # they must be different\n",
    "#                 idx_argument_2 = randint(0, len(case[\"arguments\"]) - 1)\n",
    "#             argument_1 = case[\"arguments\"][idx_argument_1]\n",
    "#             argument_2 = case[\"arguments\"][idx_argument_2]\n",
    "#             type_relation = randint(0,9)\n",
    "#             if type_relation < 3: # with 30% chance we select two premises\n",
    "#                 id_1 = randint(0, len(argument_1[\"premises\"]) - 1)\n",
    "#                 id_2 = randint(0, len(argument_2[\"premises\"]) - 1)\n",
    "#                 id_1 = argument_1[\"premises\"][id_1]\n",
    "#                 id_2 = argument_2[\"premises\"][id_2]\n",
    "#                 if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples): # only if the couple is not already present in the dataset\n",
    "#                     unrelated.append({\n",
    "#                         \"e2\": clauses[id_1],\n",
    "#                         \"e1\": clauses[id_2]\n",
    "#                     })\n",
    "#                     n_unrelated_two_premises += 1\n",
    "#                     already_taken_couples.add(id_1 + id_2)\n",
    "#                     break\n",
    "#             elif type_relation < 6: # with 30% chance we select a premise and a conclusion\n",
    "#                 prem = randint(0, 1) # we select the premise argument at random\n",
    "#                 args = [argument_1, argument_2]\n",
    "#                 id_1 = randint(0, len(args[prem][\"premises\"]) - 1)\n",
    "#                 id_1 = args[prem][\"premises\"][id_1]\n",
    "#                 id_2 = args[abs(prem - 1)][\"conclusion\"] # the other argument gives the conclusion\n",
    "#                 if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples): # only if the couple is not already present in the dataset\n",
    "#                     n_unrelated_premise_conclusion += 1\n",
    "#                     already_taken_couples.add(id_1 + id_2)\n",
    "#                     if randint(0, 5) > 5: # with 50% chance we put the premise first \n",
    "#                         unrelated.append({\n",
    "#                             \"e2\": clauses[id_1],\n",
    "#                             \"e1\": clauses[id_2]\n",
    "#                         })\n",
    "#                     else: # with 50% chance we put the conclusion first \n",
    "#                         unrelated.append({\n",
    "#                             \"e2\": clauses[id_2],\n",
    "#                             \"e1\": clauses[id_1]\n",
    "#                         })\n",
    "#                     break\n",
    "#             else: # with 30% chance we select 2 conclusions\n",
    "#                 id_1 = argument_1[\"conclusion\"]\n",
    "#                 id_2 = argument_2[\"conclusion\"]\n",
    "#                 if not (id_1 + id_2 in already_taken_couples or id_2 + id_1 in already_taken_couples): # only if the couple is not already present in the dataset\n",
    "#                     unrelated.append({\n",
    "#                         \"e2\": clauses[id_1],\n",
    "#                         \"e1\": clauses[id_2]\n",
    "#                     })\n",
    "#                     n_unrelated_two_conclusions += 1\n",
    "#                     already_taken_couples.add(id_1 + id_2)\n",
    "#                     break\n",
    "\n",
    "#     for related_elem in related: # add all the new elements to the dataset\n",
    "#         ARM_x.append(related_elem)\n",
    "#         ARM_y.append(torch.tensor([1., 0]))\n",
    "#     for unrelated_elem in unrelated:\n",
    "#         ARM_x.append(unrelated_elem)\n",
    "#         ARM_y.append(torch.tensor([0, 1.]))\n",
    "        \n",
    "# assert len([y for y in ARM_y if y[0] == 0]) == (n_unrelated_two_premises + n_unrelated_premise_conclusion + n_unrelated_two_conclusions)\n",
    "# assert len([y for y in ARM_y if y[0] == 1.]) == (n_related_premise_conclusion + n_related_two_premises) \n",
    "# print(f\"\"\"\n",
    "# There are:\n",
    "#       - {len(ARM_x)} couples\n",
    "#       - {n_related_two_premises + n_related_premise_conclusion} related clauses:\n",
    "#         - {n_related_two_premises} are couple of clauses both premises on the same argument\n",
    "#         - {n_related_premise_conclusion} are couple of clauses premise and conclusion on the same argument\n",
    "#       - {n_unrelated_two_premises + n_unrelated_premise_conclusion + n_unrelated_two_conclusions} unrelated clauses:\n",
    "#         - {n_unrelated_two_premises} are couple with two premises from different arguments\n",
    "#         - {n_unrelated_premise_conclusion} are couple with a premise and a conclusion from two different arguments\n",
    "#         - {n_unrelated_two_conclusions} are couple with two conclusions from different arguments\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10430\n",
      "5161 5269\n"
     ]
    }
   ],
   "source": [
    "args_set = set()    #Prepare ids of clauses that are parts of arguments\n",
    "for case in refactored_dataset: # for each case\n",
    "    for argument in case[\"arguments\"]: \n",
    "        args_set.add(argument[\"conclusion\"])\n",
    "        for premise in argument[\"premises\"]:\n",
    "            args_set.add(premise)\n",
    "\n",
    "ARM_x = []\n",
    "ARM_y = []\n",
    "for caseidx in range(len(dataset)):\n",
    "    sorted_clauses = sorted(dataset[caseidx]['clauses'], key = lambda x: x['start'])\n",
    "    for i in range(len(sorted_clauses)-1):\n",
    "        if sorted_clauses[i]['_id'] in args_set:\n",
    "            for el in sorted_clauses[i+1:i+6]:\n",
    "                if el['_id'] in args_set:\n",
    "                    ARM_x.append({'e1': refactored_dataset[caseidx]['all_clauses'][sorted_clauses[i]['_id']], 'e2': refactored_dataset[caseidx]['all_clauses'][el['_id']]})\n",
    "                    y = torch.tensor([0, 1.])\n",
    "                    for arg in refactored_dataset[caseidx]['arguments']:\n",
    "                        if sorted_clauses[i]['_id'] in arg['premises'] or sorted_clauses[i]['_id'] == arg['conclusion']:\n",
    "                            if el['_id'] in arg['premises'] or sorted_clauses[i]['_id'] == arg['conclusion']:\n",
    "                                y = torch.tensor([1., 0])\n",
    "                    ARM_y.append(y)\n",
    "\n",
    "print(len(ARM_x))\n",
    "print(len([ARM_y[i] for i in range(len(ARM_y)) if ARM_y[i][0]]), len([ARM_y[i] for i in range(len(ARM_y)) if not ARM_y[i][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1 prende le due componenti e le analizza indipendentemente per poi dare un output\n",
    "\n",
    "Molel2 concatena componente 1 e componente 2 per analizzarle assieme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class Model1(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = .3) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size * 2, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _, encoded_input_1 = self.encoder(**input[\"e1\"], return_dict = False)\n",
    "        _, encoded_input_2 = self.encoder(**input[\"e2\"], return_dict = False)\n",
    "        encoded_input = self.dropout(torch.cat((encoded_input_1, encoded_input_2), dim=1))\n",
    "    \n",
    "        return self.output_layer(encoded_input)\n",
    "    \n",
    "class Model2(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = .3) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = {key: torch.cat((input[\"e1\"][key], input[\"e2\"][key]), dim=1) for key in input[\"e1\"].keys()}\n",
    "        _, encoded_input = self.encoder(**input, return_dict = False)\n",
    "        encoded_input = self.dropout(encoded_input)\n",
    "    \n",
    "        return self.output_layer(encoded_input)\n",
    "\n",
    "model1 = Model1(2)\n",
    "model2 = Model2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARM_x_tokenized = dict_lists_to_list_of_dicts({\n",
    "    key : dict_lists_to_list_of_dicts(tokenizer([v[key] for v in ARM_x], padding=True, truncation=True, return_tensors='pt'))\n",
    "for key in ARM_x[0].keys()})\n",
    "train_dataloader, validation_dataloader, test_dataloader = get_dataloader(ARM_x_tokenized, ARM_y, 8, [9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.696 - validation loss:      0.711                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.500 - validation accuracy:      0.527\n",
      "EPOCH 1 training f1_score:      0.328 - validation f1_score:      0.513\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.696 - validation loss:      0.712                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.501 - validation accuracy:      0.527\n",
      "EPOCH 2 training f1_score:      0.324 - validation f1_score:      0.513\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.696 - validation loss:      0.712                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.501 - validation accuracy:      0.530\n",
      "EPOCH 3 training f1_score:      0.330 - validation f1_score:      0.516\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.695 - validation loss:      0.712                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.499 - validation accuracy:      0.534\n",
      "EPOCH 4 training f1_score:      0.337 - validation f1_score:      0.463\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 training loss:      0.695 - validation loss:      0.712                                                                                                                                                                                                                                                      \n",
      "EPOCH 5 training accuracy:      0.499 - validation accuracy:      0.534\n",
      "EPOCH 5 training f1_score:      0.333 - validation f1_score:      0.487\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data =   model1.train_network(train_dataloader, \n",
    "                    validation_dataloader, \n",
    "                    torch.optim.SGD, \n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    device=device, \n",
    "                    batch_size=32,\n",
    "                    verbose=True, \n",
    "                    output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                    metrics={\n",
    "                     \"accuracy\": accuracy_score, \n",
    "                     \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                    learning_rate=1e-5,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.699 - validation loss:      0.721                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.500 - validation accuracy:      0.473\n",
      "EPOCH 1 training f1_score:      0.323 - validation f1_score:      0.445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.697 - validation loss:      0.717                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.500 - validation accuracy:      0.473\n",
      "EPOCH 2 training f1_score:      0.324 - validation f1_score:      0.445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.696 - validation loss:      0.715                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.499 - validation accuracy:      0.473\n",
      "EPOCH 3 training f1_score:      0.325 - validation f1_score:      0.445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.695 - validation loss:      0.713                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.499 - validation accuracy:      0.473\n",
      "EPOCH 4 training f1_score:      0.329 - validation f1_score:      0.445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 training loss:      0.695 - validation loss:      0.713                                                                                                                                                                                                                                                      \n",
      "EPOCH 5 training accuracy:      0.499 - validation accuracy:      0.473\n",
      "EPOCH 5 training f1_score:      0.326 - validation f1_score:      0.445\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data =   model2.train_network(train_dataloader, \n",
    "                    validation_dataloader, \n",
    "                    torch.optim.SGD, \n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    device=device, \n",
    "                    batch_size=32,\n",
    "                    verbose=True, \n",
    "                    output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                    metrics={\n",
    "                     \"accuracy\": accuracy_score, \n",
    "                     \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                    learning_rate=1e-5,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Premise/Conclusion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are:\n",
      "      - 662 conclusions\n",
      "      - 1857 premises\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PCR_x = []\n",
    "PCR_y = []\n",
    "all_premises = set()\n",
    "all_conclusions = set()\n",
    "all_clause = set()\n",
    "for case in refactored_dataset:\n",
    "    n_clauses = case[\"n_clauses\"]\n",
    "    clauses = case[\"all_clauses\"]\n",
    "    for argument in case[\"arguments\"]:\n",
    "        all_conclusions.add(clauses[argument[\"conclusion\"]])\n",
    "        all_clause.add(clauses[argument[\"conclusion\"]])\n",
    "        for premise in argument[\"premises\"]:\n",
    "            all_premises.add(clauses[premise])\n",
    "            all_clause.add(clauses[premise])\n",
    "\n",
    "for clause in all_clause:\n",
    "    current_y = torch.zeros(2)\n",
    "    if clause in all_premises:\n",
    "        current_y[0] = 1\n",
    "    if clause in all_conclusions:\n",
    "        current_y[1] = 1\n",
    "    PCR_x.append(clause)\n",
    "    PCR_y.append(current_y)\n",
    "print(f\"\"\"\n",
    "There are:\n",
    "      - {len([y for y in PCR_y if y[1] == 1])} conclusions\n",
    "      - {len([y for y in PCR_y if y[0] == 1])} premises\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
