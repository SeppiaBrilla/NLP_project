{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load\n",
    "import numpy as np\n",
    "from neuralNetwork import NeuralNetwork, In_between_epochs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from random import shuffle, randint\n",
    "from transformers import RobertaModel, RobertaTokenizer, AutoTokenizer, AutoModel\n",
    "from helper import dict_lists_to_list_of_dicts, get_train_valdiation_test_split, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ECHR_Corpus.json\",encoding= 'utf-8')\n",
    "dataset = load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "ogni caso nel dataset è organizzato così:\n",
    "```json\n",
    "{\n",
    "    \"text\":\"il testo completo della sentenza\"\n",
    "    \"clauses\":[\n",
    "        {\n",
    "            \"_id\": \"id della clause\",\n",
    "            \"start\": \"index di inizio della clause\",\n",
    "            \"end\": \"index di fine della cluause\"\n",
    "        },\n",
    "        {\n",
    "            \"...\":\"...\"\n",
    "        }\n",
    "    ]\n",
    "    \"argument\":[\n",
    "        {\n",
    "            \"premises\":[\n",
    "                \"id premise1\", \"id premise2\", \"...\"\n",
    "            ],\n",
    "            \"conclusion\": \"id conclusion\"\n",
    "        },\n",
    "        {\n",
    "            \"...\":\"...\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "In questo passaggio riorganizzo i dati per avere comunque la stessa struttura ma trasformo le clauses in un dizionario che ha come id la chiave della clause e come valore il testo (senza quindi dover usare start e end per cercarlo nel testo). Non tutte le clause sono parte di una premessa o di una conclusione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "refactored_dataset = []\n",
    "for datapoint in dataset:\n",
    "    text = datapoint[\"text\"]\n",
    "    dict_clauses = {}\n",
    "    for clause in datapoint[\"clauses\"]:\n",
    "        start = clause[\"start\"]\n",
    "        end = clause[\"end\"]\n",
    "        id = clause[\"_id\"]\n",
    "        dict_clauses[id] = text[start:end]\n",
    "    refactored_dataset.append({\n",
    "        \"text\": text,\n",
    "        \"arguments\": datapoint[\"arguments\"],\n",
    "        \"n_clauses\": len(datapoint[\"clauses\"]),\n",
    "        \"all_clauses\": dict_clauses\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondo me ha poco senso salvare il dataset come dataframe dato che è praticamente solo testo. Comunque non dovrebbe essere difficilissimo tirarci fuori qualche statistica. Ho fatto degli esempi scemi qua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On average, a case has 248.95 clauses with a median of 226 clauses per case.\n",
      "On average, a case has 17.69 arguments with a median of 14 arguments per case.\n",
      "Each argument, on average, has: 2.63 premises with a median of 2 premises per argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_arguments = []\n",
    "n_premises = []\n",
    "n_clauses = []\n",
    "for case in refactored_dataset:\n",
    "    n_arguments.append(len(case[\"arguments\"]))\n",
    "    n_clauses.append(case[\"n_clauses\"])\n",
    "    for argument in case[\"arguments\"]:\n",
    "        n_premises.append(len(argument[\"premises\"]))\n",
    "print(f\"\"\"\n",
    "On average, a case has {np.mean(n_clauses):.2f} clauses with a median of {np.median(n_clauses):.0f} clauses per case.\n",
    "On average, a case has {np.mean(n_arguments):.2f} arguments with a median of {np.median(n_arguments):.0f} arguments per case.\n",
    "Each argument, on average, has: {np.mean(n_premises):.2f} premises with a median of {np.median(n_premises):.0f} premises per argument.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qua puoi vedere come tirare fuori il testo di una conclusion o di una premise: ti basta usare la conclusion/premise come indice nel dizionario delle clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here an example of an argument:\n",
      "    - Premises:\n",
      "        The Commission notes that the applicant was detained after having been sentenced by the first instance court to 18 months' imprisonment.\n",
      "\tHe was released after the Court of Appeal reviewed this sentence, reducing it to 15 months' imprisonment, convertible to a fine.\n",
      "    - Conclusion:\n",
      "        The Commission finds that the applicant was deprived of his liberty \"after conviction by a competent court\" within the meaning of Article 5 para. 1 (a) (Art. 5-1-a) of the Convention.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "premise = \"\\n\\t\".join([refactored_dataset[0][\"all_clauses\"][premise] for premise in refactored_dataset[0][\"arguments\"][0][\"premises\"]])\n",
    "conclusion = refactored_dataset[0][\"all_clauses\"][refactored_dataset[0][\"arguments\"][0][\"conclusion\"]]\n",
    "print(f\"\"\"\n",
    "Here an example of an argument:\n",
    "    - Premises:\n",
    "        {premise}\n",
    "    - Conclusion:\n",
    "        {conclusion}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Argument Clause Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = get_train_valdiation_test_split(refactored_dataset, [4])#, seed = 42) #42, 4, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 28 cases in the training set (fold 0), \n",
      "    6 cases in the validation set (fold 0) and\n",
      "    8 cases in the test set (fold 0)\n",
      "    \n",
      "there are 28 cases in the training set (fold 1), \n",
      "    6 cases in the validation set (fold 1) and\n",
      "    8 cases in the test set (fold 1)\n",
      "    \n",
      "there are 28 cases in the training set (fold 2), \n",
      "    6 cases in the validation set (fold 2) and\n",
      "    8 cases in the test set (fold 2)\n",
      "    \n",
      "there are 28 cases in the training set (fold 3), \n",
      "    6 cases in the validation set (fold 3) and\n",
      "    8 cases in the test set (fold 3)\n",
      "    \n",
      "there are 28 cases in the training set (fold 4), \n",
      "    6 cases in the validation set (fold 4) and\n",
      "    8 cases in the test set (fold 4)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cases)):\n",
    "    train_cases, validation_cases, test_cases = cases[i]\n",
    "    print(f\"\"\"there are {len(train_cases)} cases in the training set (fold {i}), \n",
    "    {len(validation_cases)} cases in the validation set (fold {i}) and\n",
    "    {len(test_cases)} cases in the test set (fold {i})\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dato che non tutte le clause sono parte di una premise/conclusion, le dividiamo per cercare di tirare fuori un classificatore di clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:\n",
      "\n",
      "    There are:\n",
      "        - 3355 clause\n",
      "        - 1846 true clause\n",
      "        - 1509 fake clause\n",
      "    \n",
      "validation set:\n",
      "\n",
      "    There are:\n",
      "        - 288 clause\n",
      "        - 223 true clause\n",
      "        - 65 fake clause\n",
      "    \n",
      "test set:\n",
      "\n",
      "    There are:\n",
      "        - 1046 clause\n",
      "        - 624 true clause\n",
      "        - 422 fake clause\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def get_acr_dataloader(cases, tokenizer, batch_size=16, shuffle=False, verbose=True):\n",
    "    ACR_x = []\n",
    "    ACR_y = []\n",
    "    for case in cases:\n",
    "        n_clauses = case[\"n_clauses\"]\n",
    "        clauses = case[\"all_clauses\"]\n",
    "        args_set = set()\n",
    "        splitter = \"AS TO THE LAW\" if \"AS TO THE LAW\" in case[\"text\"] else \"THE LAW\"\n",
    "        law_section = case[\"text\"].split(splitter)[1]\n",
    "        for argument in case[\"arguments\"]:\n",
    "            if not argument[\"conclusion\"] in args_set and clauses[argument[\"conclusion\"]] in law_section:\n",
    "                ACR_x.append(clauses[argument[\"conclusion\"]])\n",
    "                ACR_y.append(torch.tensor([1.,0.]))\n",
    "                args_set.add(argument[\"conclusion\"])\n",
    "            for premise in argument[\"premises\"]:\n",
    "                if not premise in args_set and clauses[premise] in law_section:\n",
    "                    ACR_x.append(clauses[premise])\n",
    "                    ACR_y.append(torch.tensor([1.,0.]))\n",
    "                    args_set.add(premise)\n",
    "        for clause_id in clauses.keys():\n",
    "            if not clause_id in args_set and clauses[clause_id] in law_section:\n",
    "                ACR_x.append(clauses[clause_id])\n",
    "                ACR_y.append(torch.tensor([0.,1.]))\n",
    "    if verbose:\n",
    "        print(f\"\"\"\n",
    "    There are:\n",
    "        - {len(ACR_x)} clause\n",
    "        - {len([a for a in ACR_y if a[0] == 1])} true clause\n",
    "        - {len([a for a in ACR_y if a[0] == 0])} fake clause\n",
    "    \"\"\")\n",
    "    ACR_x_tokenized = dict_lists_to_list_of_dicts(tokenizer(ACR_x, padding=True, truncation=True, return_tensors='pt'))\n",
    "    dataset = Dataset(ACR_x_tokenized, ACR_y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "train_cases, validation_cases, test_cases = cases[-1]\n",
    "print(\"train set:\")\n",
    "train_dataloader = get_acr_dataloader(train_cases, tokenizer, shuffle=True, batch_size=8)\n",
    "print(\"validation set:\")\n",
    "validation_dataloder = get_acr_dataloader(validation_cases, tokenizer, batch_size=8)\n",
    "print(\"test set:\")\n",
    "test_dataloader = get_acr_dataloader(test_cases, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Da qui in avanti ti dovrebbe essere tutto abbastanza familiare dato che è praticamente lo stesso codice dell'assignment 2. Qua ho fatto solo 5 epoche e con un learning rate a caso ma è giusto per far vedere come funziona. Da ora si può iniziare a giocare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        encoded_input, _ = self.encoder(**input, return_dict = False)\n",
    "        encoded_input = self.dropout(encoded_input)\n",
    "        encoded_input = torch.nn.functional.avg_pool1d(\n",
    "            encoded_input.permute(0, 2, 1), \n",
    "            kernel_size=encoded_input.size(1)\n",
    "        ).squeeze(2)\n",
    "        if len(encoded_input.size()) != 2:\n",
    "            print(encoded_input.size())\n",
    "        return self.output_layer(encoded_input).float()\n",
    "\n",
    "    def freeze_bert(self):\n",
    "        for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "    def unfreeze_bert(self):\n",
    "        for param in self.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "model = Model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operating on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"operating on device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(In_between_epochs):\n",
    "    def __init__(self, delta, patience):\n",
    "        self.delta = delta\n",
    "        self.patience = patience\n",
    "        self.current_patience = 0\n",
    "        self.best_valid_loss = 100000000000000000000\n",
    "        self.best_model = Model(2)\n",
    "        self.epochs = 0\n",
    "    \n",
    "    def __call__(self, model:torch.nn.Module, loaders:dict[str,torch.utils.data.DataLoader], device:'torch.device|str', output_extraction_function, losses:dict[str, float]) -> bool:\n",
    "        self.epochs += 1\n",
    "        if losses[\"validation\"] < self.best_valid_loss - self.delta:\n",
    "            self.best_valid_loss = losses[\"validation\"]\n",
    "            self.best_model.load_state_dict(model.state_dict())\n",
    "            self.current_patience = 0\n",
    "        else:\n",
    "            self.current_patience += 1\n",
    "            if self.current_patience >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "    def reset(self):\n",
    "        self.current_patience = 0\n",
    "        self.epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train, validation, min_lr, start_lr, early_stopping, frac):\n",
    "    tot_train_data, tot_val_data = [], []\n",
    "    lr = start_lr\n",
    "    while lr > min_lr:\n",
    "        train_data, validation_data = model.train_network(train, \n",
    "                        validation, \n",
    "                        torch.optim.Adam, \n",
    "                        loss_function=nn.CrossEntropyLoss(),\n",
    "                        device=device, \n",
    "                        batch_size=32,\n",
    "                        verbose=True, \n",
    "                        output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                        metrics={\n",
    "                        \"accuracy\": accuracy_score, \n",
    "                        \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                        in_between_epochs = {\"early_stopping\": early_stopping},\n",
    "                        learning_rate=lr,\n",
    "                        epochs=2)\n",
    "        train_data[\"epochs\"] = early_stopping.epochs\n",
    "        train_data[\"lr\"] = lr\n",
    "        validation_data[\"epochs\"] = early_stopping.epochs\n",
    "        validation_data[\"lr\"] = lr\n",
    "        tot_train_data.append(train_data)\n",
    "        tot_val_data.append(validation_data)\n",
    "        model.load_state_dict(early_stopping.best_model.state_dict())\n",
    "        lr = lr * frac\n",
    "        early_stopping.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_train(lrs:list[float], train, validation):\n",
    "    trainings = []\n",
    "    models = []\n",
    "    for lr in lrs:\n",
    "        model = Model(2)\n",
    "        train_data, validation_data = model.train_network(train, \n",
    "                        validation, \n",
    "                        torch.optim.Adam, \n",
    "                        loss_function=nn.CrossEntropyLoss(),\n",
    "                        device=device, \n",
    "                        batch_size=32,\n",
    "                        verbose=True, \n",
    "                        output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                        metrics={\n",
    "                        \"accuracy\": accuracy_score, \n",
    "                        \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                        learning_rate=lr,\n",
    "                        epochs=15)\n",
    "        for key in train_data:\n",
    "                train_data[key] = [float(v) for v in train_data[key]]\n",
    "                validation_data[key] = [float(v) for v in validation_data[key]]\n",
    "        trainings.append({\"train\": train_data, \"validation\":validation_data, \"lr\":lr})\n",
    "        models.append(model)\n",
    "    return trainings, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_training(cases):\n",
    "    best_models = []\n",
    "    for cases_split in cases:\n",
    "        train_cases, validation_cases, _ = cases_split\n",
    "        train_dataloader = get_acr_dataloader(train_cases, tokenizer, shuffle=True, batch_size=8, verbose=False)\n",
    "        validation_dataloder = get_acr_dataloader(validation_cases, tokenizer, batch_size=8, verbose=False)\n",
    "        model = Model(2)\n",
    "        early_stopping = EarlyStopping(.001, 3)\n",
    "        train(model, train_dataloader, validation_dataloder, 5e-7, 1e-6, early_stopping, .6)\n",
    "        model.load_state_dict(early_stopping.best_model.state_dict())\n",
    "        best_models.append({\"loss\": early_stopping.best_valid_loss, \"model\": model})\n",
    "    \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.589 - validation loss:      0.656                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.701 - validation accuracy:      0.651\n",
      "EPOCH 1 training f1_score:      0.618 - validation f1_score:      0.489\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.499 - validation loss:      0.700                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.761 - validation accuracy:      0.660\n",
      "EPOCH 2 training f1_score:      0.716 - validation f1_score:      0.499\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.533 - validation loss:      0.706                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.736 - validation accuracy:      0.605\n",
      "EPOCH 1 training f1_score:      0.691 - validation f1_score:      0.435\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.493 - validation loss:      0.690                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.766 - validation accuracy:      0.636\n",
      "EPOCH 2 training f1_score:      0.727 - validation f1_score:      0.478\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.629 - validation loss:      0.666                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.686 - validation accuracy:      0.597\n",
      "EPOCH 1 training f1_score:      0.564 - validation f1_score:      0.533\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.522 - validation loss:      0.617                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.751 - validation accuracy:      0.662\n",
      "EPOCH 2 training f1_score:      0.678 - validation f1_score:      0.540\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.490 - validation loss:      0.617                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.770 - validation accuracy:      0.667\n",
      "EPOCH 1 training f1_score:      0.705 - validation f1_score:      0.543\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.463 - validation loss:      0.625                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.791 - validation accuracy:      0.669\n",
      "EPOCH 2 training f1_score:      0.734 - validation f1_score:      0.544\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.628 - validation loss:      0.644                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.680 - validation accuracy:      0.649\n",
      "EPOCH 1 training f1_score:      0.619 - validation f1_score:      0.514\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.538 - validation loss:      0.592                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.731 - validation accuracy:      0.684\n",
      "EPOCH 2 training f1_score:      0.667 - validation f1_score:      0.571\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.503 - validation loss:      0.570                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.756 - validation accuracy:      0.697\n",
      "EPOCH 1 training f1_score:      0.704 - validation f1_score:      0.583\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.476 - validation loss:      0.556                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.779 - validation accuracy:      0.696\n",
      "EPOCH 2 training f1_score:      0.735 - validation f1_score:      0.555\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.635 - validation loss:      0.614                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.645 - validation accuracy:      0.716\n",
      "EPOCH 1 training f1_score:      0.511 - validation f1_score:      0.636\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.538 - validation loss:      0.502                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.717 - validation accuracy:      0.809\n",
      "EPOCH 2 training f1_score:      0.638 - validation f1_score:      0.682\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.492 - validation loss:      0.505                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.768 - validation accuracy:      0.788\n",
      "EPOCH 1 training f1_score:      0.729 - validation f1_score:      0.614\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.476 - validation loss:      0.476                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.762 - validation accuracy:      0.817\n",
      "EPOCH 2 training f1_score:      0.708 - validation f1_score:      0.673\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.649 - validation loss:      0.621                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.661 - validation accuracy:      0.781\n",
      "EPOCH 1 training f1_score:      0.574 - validation f1_score:      0.651\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.569 - validation loss:      0.504                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.707 - validation accuracy:      0.816\n",
      "EPOCH 2 training f1_score:      0.637 - validation f1_score:      0.682\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 1 training loss:      0.532 - validation loss:      0.484                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.733 - validation accuracy:      0.812\n",
      "EPOCH 1 training f1_score:      0.679 - validation f1_score:      0.653\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.510 - validation loss:      0.470                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.745 - validation accuracy:      0.799\n",
      "EPOCH 2 training f1_score:      0.695 - validation f1_score:      0.652\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = fold_training(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model loss: 0.47013330459594727\n"
     ]
    }
   ],
   "source": [
    "best_model_fold = min(models, key= lambda x: x[\"loss\"]) \n",
    "print(f\"best model loss: {best_model_fold['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_fold['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_fold['model'].state_dict(), 'best model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Model(2)\n",
    "best_model.load_state_dict(best_model_fold[\"model\"].state_dict())\n",
    "best_model = best_model.to(device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "1904\n",
      "accuracy: 0.86\n",
      "    f1: 0.89\n",
      "    precision: 0.92\n",
      "    recall: 0.86\n"
     ]
    }
   ],
   "source": [
    "def full_test(model, cases):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for case in cases:\n",
    "            clauses = case[\"all_clauses\"]\n",
    "            args_set = set()\n",
    "            splitter = \"AS TO THE LAW\" if \"AS TO THE LAW\" in case[\"text\"] else \"THE LAW\"\n",
    "            law_section = case[\"text\"].split(splitter)[1]\n",
    "            for argument in case[\"arguments\"]:\n",
    "                if (argument[\"conclusion\"] not in args_set) and (clauses[argument[\"conclusion\"]] in law_section):\n",
    "                    tokenized_x = tokenizer(clauses[argument[\"conclusion\"]],padding = True, truncation=True, return_tensors='pt')\n",
    "                    tokenized_x = {key: tokenized_x[key].to(device) for key in tokenized_x.keys()}\n",
    "                    pred = model(tokenized_x)\n",
    "                    y_pred.append(torch.max(pred, -1)[1].view(-1).cpu().tolist()[0])\n",
    "                    y_true.append(0)\n",
    "                    keys = list(tokenized_x.keys())\n",
    "                    for k in keys:\n",
    "                        del tokenized_x[k]\n",
    "                    del tokenized_x\n",
    "                    args_set.add(argument[\"conclusion\"])\n",
    "                elif argument[\"conclusion\"] not in args_set and clauses[argument[\"conclusion\"]] not in law_section:\n",
    "                    args_set.add(argument[\"conclusion\"])\n",
    "                    y_pred.append(1)\n",
    "                    y_true.append(0)\n",
    "                for premise in argument[\"premises\"]:\n",
    "                    if premise not in args_set and clauses[premise] in law_section:\n",
    "                        tokenized_x = tokenizer(clauses[premise], padding = True, truncation=True, return_tensors='pt')\n",
    "                        tokenized_x = {key: tokenized_x[key].to(device) for key in tokenized_x.keys()}\n",
    "                        pred = model(tokenized_x)\n",
    "                        y_pred.append(torch.max(pred, -1)[1].view(-1).cpu().tolist()[0])\n",
    "                        y_true.append(0)\n",
    "                        keys = list(tokenized_x.keys())\n",
    "                        for k in keys:\n",
    "                            del tokenized_x[k]\n",
    "                        del tokenized_x\n",
    "                        args_set.add(premise)\n",
    "                        \n",
    "                    elif premise not in args_set and clauses[premise] not in law_section:\n",
    "                        args_set.add(premise)\n",
    "                        y_pred.append(1)\n",
    "                        y_true.append(0)\n",
    "            for clause_id in clauses.keys():\n",
    "                if (not clause_id in args_set) and (clauses[clause_id] in law_section):\n",
    "                    tokenized_x = tokenizer(clauses[clause_id], padding = True, truncation=True, return_tensors='pt')\n",
    "                    tokenized_x = {key: tokenized_x[key].to(device) for key in tokenized_x.keys()}\n",
    "                    pred = model(tokenized_x)\n",
    "                    y_pred.append(torch.max(pred, -1)[1].view(-1).cpu().tolist()[0])\n",
    "                    y_true.append(1)\n",
    "                    keys = list(tokenized_x.keys())\n",
    "                    for k in keys:\n",
    "                        del tokenized_x[k]\n",
    "                    del tokenized_x\n",
    "                    args_set.add(clause_id)\n",
    "                    \n",
    "                #else:\n",
    "                if (not clause_id in args_set) and (clauses[clause_id] not in law_section):\n",
    "                    y_pred.append(1)\n",
    "                    y_true.append(1)\n",
    "    print(y_true)\n",
    "    print(y_pred)\n",
    "    print(len(y_true))\n",
    "    print(f\"\"\"accuracy: {accuracy_score(y_true, y_pred):.2f}\n",
    "    f1: {f1_score(y_true, y_pred):.2f}\n",
    "    precision: {precision_score(y_true, y_pred):.2f}\n",
    "    recall: {recall_score(y_true, y_pred):.2f}\"\"\")\n",
    "full_test(best_model, test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5d4b80113e582511aa1cd850': \" The\\r\\nCommission, taking into account the applicant's position in these\\r\\nproceedings and the impact of their outcome on her own financial\\r\\nsituation,\",\n",
       " '5d4b802b3e582511aa1cd851': 'finds that the applicant is entitled to complain about the\\r\\nlength of the proceedings.\\r',\n",
       " '5d4b804a3e582511aa1cd852': 'They submit that the applicant\\r\\nfailed to complain about the length in the course of the domestic court\\r\\nproceedings and did not lodge a request under S. 91 of the Court\\r\\nOrganisation Act 1990 (Gerichtsverfassungsgesetz) that, in view of the\\r\\nalleged delay, the superior court should fix an appropriate time-limit\\r\\nfor the conduct of the court proceedings.\\r',\n",
       " '5d4b80613e582511aa1cd853': 'According to Article 26 (Art. 26), the \"Commission may only deal\\r\\nwith the matter after all domestic remedies have been exhausted,\\r\\naccording to the generally recognised rules of international law\".\\r\\n\\r',\n",
       " '5d4b80763e582511aa1cd854': 'The Government maintain that the applicant failed to exhaust, as\\r\\nrequired by Article 26 (Art. 26) of the Convention, the remedies\\r\\navailable to her under Austrian law.',\n",
       " '5d4b809e3e582511aa1cd855': ' The Commission notes that S. 91 of the Austrian Court\\r\\nOrganisation Act, which entitles the parties to court proceedings to\\r\\nlodge a request with the superior court to fix a time limit in respect\\r\\nof a delayed procedural step, entered into force on 1 January 1990 when\\r\\nthe proceedings in question were already pending for one year.',\n",
       " '5d4b80b53e582511aa1cd856': \"At that\\r\\nstage, the District Court had already been dealing with the applicant's\\r\\nrequest of December 1988 and, in its decision of 10 August 1989,\\r\\npostponed the examination thereof, and the Regional Court had decided\\r\\non the applicant's appeal on 29 November 1989.\\r\",\n",
       " '5d4b80ce3e582511aa1cd857': 'The Commission finds that it is thus not faced with the issue of\\r\\nan alleged absence of any reaction of the competent court to a\\r\\nprocedural request (cf. No. 19369/92, Dec. 8.1.93, not published).',\n",
       " '5d4b80f23e582511aa1cd858': 'The Commission finds that it is thus not faced with the issue of\\r\\nan alleged absence of any reaction of the competent court to a\\r\\nprocedural request (cf. No. 19369/92, Dec. 8.1.93, not published).',\n",
       " '5d4b81133e582511aa1cd859': 'In\\r\\nthe circumstances of the present case, a request under S. 91 of the\\r\\nCourt Organisation Act cannot be considered as an effective remedy to\\r\\nensure, regarding the proceedings as a whole, a determination of the\\r\\napplicant\\'s civil rights and obligations within a \"reasonable time\"\\r\\nwithin the meaning of Article 6 para. 1 (Art. 6-1) of the Convention.\\r',\n",
       " '5d4b81223e582511aa1cd85a': 'The application cannot, therefore, be rejected for non-compliance\\r\\nwith the condition as to the exhaustion of domestic remedies under\\r\\nArticle 26 (Art. 26) of the Convention.\\r',\n",
       " '5d4b81533e582511aa1cd85b': 'As regards the merits of the complaint, the Government, referring\\r\\nto the case-law of the Convention organs, argue that the length of the\\r\\nproceedings was mainly due to the complexity of the case.',\n",
       " '5d4b816e3e582511aa1cd85c': 'In this\\r\\nrespect, they refer to the numerous other matters related to the\\r\\nproceedings at issue, and the proceedings before the Vienna Juvenile\\r\\nCourt.',\n",
       " '5d4b81823e582511aa1cd85d': 'They consider that no substantial delays were imputable to the\\r\\nAustrian authorities.',\n",
       " '5d4b81e33e582511aa1cd85f': 'thereby caused difficulties to survey the file and to\\r\\ndecide upon all of her requests in due time.\\r',\n",
       " '5d4b822c3e582511aa1cd861': ' According to the Government, the applicant\\r\\nherself was responsible for the delays in',\n",
       " '5d4b824f3e582511aa1cd862': 'that she filed numerous\\r\\nsubmissions',\n",
       " '5d4b828a3e582511aa1cd863': 'The Commission considers, in the light of the criteria\\r\\nestablished by the case-law of the Convention institutions on the\\r\\nquestion of \"reasonable time\"',\n",
       " '5d4b829f3e582511aa1cd864': 'the complexity of the case,',\n",
       " '5d4b82c83e582511aa1cd865': \"the\\r\\napplicant's conduct and that of the competent authorities), and having\\r\\nregard to all the information in its possession\",\n",
       " '5d4b82d83e582511aa1cd866': 'that a thorough\\r\\nexamination of this complaint is required, both as to the law and as\\r\\nto the facts.\\r',\n",
       " '5d4b82f23e582511aa1cd867': 'For these reasons, the Commission unanimously\\r\\n\\r\\n      DECLARES THE APPLICATION ADMISSIBLE,\\r\\n      without prejudging the merits of the case.\\r\\n\\r',\n",
       " '5d4d251b3e582511aa1cde5b': 'The facts, as they have been submitted by the parties, may be\\r\\nsummarised as follows.\\r\\n\\r',\n",
       " '5d4d25243e582511aa1cde5c': 'The applicant, an Austrian citizen, born in 1951, is living in\\r\\nVienna. ',\n",
       " '5d4d252c3e582511aa1cde5d': 'The applicant is the mother of three children born in wedlock\\r\\nin 1973, 1974 and 1976, respectively.',\n",
       " '5d4d25313e582511aa1cde5e': 'The spouses separated in 1982.\\r',\n",
       " '5d4d25373e582511aa1cde5f': 'The custody over the children born in 1973 and 1974 was assigned to the\\r\\napplicant, the custody over the child born in 1976 to his father.\\r',\n",
       " '5d4d253b3e582511aa1cde60': ' Since April 1977 proceedings relating to custody and other\\r\\nmatters concerning the children are pending before the Floridsdorf\\r\\nDistrict Court (Bezirksgericht).\\r',\n",
       " '5d4d25483e582511aa1cde61': ' On 31 December 1988 the applicant, on behalf of her children born\\r\\nin 1973 and 1974, applied with the Floridsdorf District Court that her\\r\\ndivorced husband be ordered to increase his maintenance payments by\\r\\nAS 600 per month and per child, as from 1 January 1989, as compared\\r\\nwith the amount of AS 4550 per child fixed by the Court on\\r\\n12 August 1986.',\n",
       " '5d4d254b3e582511aa1cde62': 'Her request was received at the Court on\\r\\n3 January 1989.\\r\\n\\r',\n",
       " '5d4d25513e582511aa1cde63': 'On 16 February 1989 the applicant challenged the judicial officer\\r\\n(Rechtspfleger) at the Floridsdorf District Court dealing with her case\\r\\nfor bias, which she withdrew on 5 May 1989.\\r',\n",
       " '5d4d25613e582511aa1cde64': 'On 10 August 1989 the Floridsdorf District Court took a decision\\r\\non various earlier requests of the applicant regarding the increase of\\r\\nthe maintenance payments in respect of periods in 1987 and 1988, and\\r\\nother financial matters. ',\n",
       " '5d4d25663e582511aa1cde65': 'The amounts of increase for these periods\\r\\nvaried between AS 200 and AS 1100 per month.',\n",
       " '5d4d256c3e582511aa1cde66': \"The Court also stated\\r\\nthat the applicant's request regarding the maintenance payments as from\\r\\n1 January 1989 would be dealt with following further investigations.\\r\",\n",
       " '5d4d25733e582511aa1cde67': 'On 25 August 1989 the applicant appealed against the decision of\\r\\n10 August 1989 with the Vienna Regional Court (Landesgericht).\\r\\n\\r',\n",
       " '5d4d25773e582511aa1cde68': 'On 1 September 1989 the applicant amended her claims regarding\\r\\nthe period as from January 1989 to amounts of increase between AS 950\\r\\nand AS 2000 per month.\\r',\n",
       " '5d4d25863e582511aa1cde69': \"On 29 November 1989 the Vienna Regional Court (Landesgericht),\\r\\nupon the applicant's appeal (Rekurs), amended the District Court's\\r\\ndecision, granting a higher increase in respect of four months in 1987,\\r\\nand dismissed the remainder of the appeal.\",\n",
       " '5d4d258a3e582511aa1cde6a': 'The decision and the files\\r\\nwere received at the District Court on 28 December 1989.\\r',\n",
       " '5d4d25933e582511aa1cde6b': \" In the beginning of 1990 the files were forwarded to the Vienna\\r\\nJuvenile Court (Jugendgerichtshof) in the context of proceedings to\\r\\nwithdraw the applicant's custody in respect of her child born in 1973.\\r\",\n",
       " '5d4d259f3e582511aa1cde6c': \"The applicant's custody was withdrawn in April 1990, the proceedings\\r\\nwere disposed of by declaring the child of full age in January 1991,\\r\\ndecision which became final in October 1992.\",\n",
       " '5d4d25a73e582511aa1cde6d': \"Proceedings regarding\\r\\nfurther financial matters, in particular the applicant's obligation to\\r\\npay maintenance for the child concerned, continued to be pending before\\r\\nthe Vienna Juvenile Court.\",\n",
       " '5d4d25b13e582511aa1cde6f': 'In May 1993, the Juvenile Court returned\\r\\nthe files.\\r',\n",
       " '5d4d25ba3e582511aa1cde70': \"On 22 October 1993 the Floridsdorf District Court partly granted\\r\\nthe applicant's request of 31 December 1988 as amended in September\\r\\n1989, to the extent that it concerned the child born in 1974.\",\n",
       " '5d4d25be3e582511aa1cde71': 'The\\r\\nCourt granted an increase which varied between AS 200 and AS 1550 per\\r\\nmonth and dismissed the remainder of her claims.\\r',\n",
       " '5d4d25c63e582511aa1cde72': \" On 7 December 1993 the Vienna Regional Court rejected the\\r\\napplicant's appeal on behalf of her child, born in 1974, meanwhile an\\r\\nadult, and dismissed the appeal brought by this child on its own.\\r\\n\\r\",\n",
       " '5d4d25cc3e582511aa1cde73': ' The applicant complains that her request relating to a rise of\\r\\nmaintenance payments for her children as from 1 January 1989 was not\\r\\ndealt with within a reasonable time.\\r',\n",
       " '5d4d25d03e582511aa1cde74': 'The application was introduced on 10 April 1993 and registered\\r\\non 7 June 1993.\\r\\n\\r',\n",
       " '5d4d25d43e582511aa1cde75': 'On 29 June 1994 the Commission decided to communicate the\\r\\napplication to the respondent Government for observations on the\\r\\nadmissibility and merits.\\r',\n",
       " '5d4d25df3e582511aa1cde76': 'On 31 October 1994, after an extension of the time-limit, the\\r\\nGovernment submitted their observations.',\n",
       " '5d4d25e73e582511aa1cde77': 'The observations in reply by\\r\\nthe applicant were submitted on 8 December 1994.\\r',\n",
       " '5d53a9c43e582511aa1ce5d7': 'The applicant complains about the length of the proceedings\\r\\nregarding her request of 31 December 1988 for an increase of\\r\\nmaintenance payments in respect of two of her children.\\r',\n",
       " '5d53a9ca3e582511aa1ce5d8': 'Article 6 para. 1 (Art. 6-1), so far as relevant, provides that\\r\\n\"in the determination of his civil rights and obligations ..., everyone\\r\\nis entitled to a ... hearing within a reasonable time\".\\r',\n",
       " '5d53a9d33e582511aa1ce5d9': 'The proceedings at issue concerned maintenance claims and fall\\r\\nto be examined under Article 6 para. 1 (Art. 6-1) of the Convention.\\r',\n",
       " '5d53a9ec3e582511aa1ce5da': 'The Commission notes that the applicant brought the proceedings on\\r\\nbehalf of her children, who were minor at the relevant time.',\n",
       " '5d53fbb23e582511aa1ce79e': 'The European Commission of Human Rights (First Chamber) sitting\\r\\nin private on 17 May 1995, the following members being present:',\n",
       " '5f94595dbf181507836fa365': 'Having regard to Article 25 of the Convention for the Protection\\r\\nof Human Rights and Fundamental Freedoms;',\n",
       " '5f945962bf181507836fa366': 'Having regard to the application introduced on 10 April 1993 by\\r\\nElisabeth Girardi against Austria and registered on 7 June 1993 under\\r\\nfile No. 21985/93;',\n",
       " '5f945966bf181507836fa367': 'Having regard to the report provided for in Rule 47 of the Rules\\r\\nof Procedure of the Commission;',\n",
       " '5f94596cbf181507836fa368': 'Having regard to the observations submitted by the respondent\\r\\nGovernment on 31 October 1994, after an extension of the time-limit and\\r\\nthe observations in reply submitted by the applicant on\\r\\n8 December 1994;',\n",
       " '5f945970bf181507836fa369': 'Having deliberated;',\n",
       " '5f945973bf181507836fa36a': 'Decides as follows:'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clauses = test_cases[0][\"all_clauses\"]\n",
    "clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_x = tokenizer(test_cases[0][\"all_clauses\"][list(test_cases[0][\"all_clauses\"].keys())[2]], truncation=True, return_tensors='pt')\n",
    "model(tokenized_x)\n",
    "\n",
    "torch.max(model(tokenized_x), -1)[1].view(-1).cpu().tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Argument Relation Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_premises(idx_1, argument):\n",
    "    idx_2 = randint(0, len(argument[\"premises\"]) - 1)\n",
    "    while idx_1 == idx_2:\n",
    "       idx_2 = randint(0, len(argument[\"premises\"]) - 1)\n",
    "    premise_1 = argument[\"premises\"][idx_1]\n",
    "    premise_2 = argument[\"premises\"][idx_2]\n",
    "    return {\n",
    "        \"e1\": clauses[premise_1],\n",
    "        \"e2\": clauses[premise_2]\n",
    "    }, (premise_1, premise_2)\n",
    "\n",
    "def add_premise_conclusion(idx_1, argument):\n",
    "    premise = argument[\"premises\"][idx_1]\n",
    "    conclusion = argument[\"conclusion\"]\n",
    "    if randint(1, 10) > 5: # with 50% chance we make the premise the first element\n",
    "        return {\n",
    "            \"e1\": clauses[premise],\n",
    "            \"e2\": clauses[conclusion]\n",
    "        }, (premise, conclusion)\n",
    "    else: # with 50% chance we make the conclusion the first element\n",
    "        return {\n",
    "            \"e2\": clauses[conclusion],\n",
    "            \"e1\": clauses[premise]\n",
    "        }, (premise, conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 7434 7434\n",
      "10430\n",
      "5161 5269\n"
     ]
    }
   ],
   "source": [
    "args_set = set()    #Prepare ids of clauses that are parts of arguments\n",
    "for case in refactored_dataset: # for each case\n",
    "    for argument in case[\"arguments\"]: \n",
    "        args_set.add(argument[\"conclusion\"])\n",
    "        for premise in argument[\"premises\"]:\n",
    "            args_set.add(premise)\n",
    "\n",
    "ARM_x = []\n",
    "ARM_y = []\n",
    "for caseidx in range(len(dataset)):\n",
    "    sorted_clauses = sorted(dataset[caseidx]['clauses'], key = lambda x: x['start'])\n",
    "    for i in range(len(sorted_clauses)-1):\n",
    "        if sorted_clauses[i]['_id'] in args_set:\n",
    "            for el in sorted_clauses[i+1:i+6]:\n",
    "                if el['_id'] in args_set:\n",
    "                    ARM_x.append({'e1': refactored_dataset[caseidx]['all_clauses'][sorted_clauses[i]['_id']], 'e2': refactored_dataset[caseidx]['all_clauses'][el['_id']]})\n",
    "                    y = torch.tensor([0., 1.])\n",
    "                    for arg in refactored_dataset[caseidx]['arguments']:\n",
    "                        if sorted_clauses[i]['_id'] in arg['premises'] or sorted_clauses[i]['_id'] == arg['conclusion']:\n",
    "                            if el['_id'] in arg['premises'] or sorted_clauses[i]['_id'] == arg['conclusion']:\n",
    "                                y = torch.tensor([1., 0.])\n",
    "                    ARM_y.append(y)\n",
    "    if caseidx == 33:\n",
    "        print(caseidx, len(ARM_x), len(ARM_y))\n",
    "\n",
    "print(len(ARM_x))\n",
    "print(len([ARM_y[i] for i in range(len(ARM_y)) if ARM_y[i][0]]), len([ARM_y[i] for i in range(len(ARM_y)) if not ARM_y[i][0]]))\n",
    "\n",
    "ARM_x_train = ARM_x[:6313] #Visto a mano, fino a indice 6312 sono nel train, fino a 7433 nel val, e il resto nel test\n",
    "ARM_y_train = ARM_y[:6313]\n",
    "ARM_x_val = ARM_x[6313:7434]\n",
    "ARM_y_val = ARM_y[6313:7434]\n",
    "ARM_x_test=ARM_x[7434:]\n",
    "ARM_y_test=ARM_y[7434:]\n",
    "\n",
    "ARM_x_train_tokenized = dict_lists_to_list_of_dicts({\n",
    "    key : dict_lists_to_list_of_dicts(tokenizer([v[key] for v in ARM_x_train], padding=True, truncation=True, return_tensors='pt'))\n",
    "for key in ARM_x_train[0].keys()})\n",
    "\n",
    "ARM_x_val_tokenized = dict_lists_to_list_of_dicts({\n",
    "    key : dict_lists_to_list_of_dicts(tokenizer([v[key] for v in ARM_x_val], padding=True, truncation=True, return_tensors='pt'))\n",
    "for key in ARM_x_val[0].keys()})\n",
    "\n",
    "ARM_x_test_tokenized = dict_lists_to_list_of_dicts({\n",
    "    key : dict_lists_to_list_of_dicts(tokenizer([v[key] for v in ARM_x_test], padding=True, truncation=True, return_tensors='pt'))\n",
    "for key in ARM_x_test[0].keys()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model1 prende le due componenti e le analizza indipendentemente per poi dare un output\n",
    "\n",
    "Molel2 concatena componente 1 e componente 2 per analizzarle assieme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = .3) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")#\"FacebookAI/roberta-base\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size * 2, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _, encoded_input_1 = self.encoder(**input[\"e1\"], return_dict = False)\n",
    "        _, encoded_input_2 = self.encoder(**input[\"e2\"], return_dict = False)\n",
    "        encoded_input = self.dropout(torch.cat((encoded_input_1, encoded_input_2), dim=1))\n",
    "    \n",
    "        return self.output_layer(encoded_input)\n",
    "    \n",
    "class Model2(NeuralNetwork):\n",
    "    def __init__(self, out_features:int, dropout:float = .3) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "        self.output_layer = nn.Linear(self.encoder.config.hidden_size, out_features)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = {key: torch.cat((input[\"e1\"][key], input[\"e2\"][key]), dim=1) for key in input[\"e1\"].keys()}\n",
    "        _, encoded_input = self.encoder(**input, return_dict = False)\n",
    "        encoded_input = self.dropout(encoded_input)\n",
    "    \n",
    "        return self.output_layer(encoded_input)\n",
    "\n",
    "model1 = Model1(2)\n",
    "model2 = Model2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARM_x_tokenized = dict_lists_to_list_of_dicts({\n",
    "#    key : dict_lists_to_list_of_dicts(tokenizer([v[key] for v in ARM_x], padding=True, truncation=True, return_tensors='pt'))\n",
    "#for key in ARM_x[0].keys()})\n",
    "#train_dataloader, validation_dataloader, test_dataloader = get_dataloader(ARM_x_tokenized, ARM_y, 8, [9])\n",
    "batch_size = 8\n",
    "train_dataloader, validation_dataloader, test_dataloader = (DataLoader(Dataset(ARM_x_train_tokenized, ARM_y_train), batch_size = batch_size, shuffle = True),\n",
    "                                                            DataLoader(Dataset(ARM_x_val_tokenized, ARM_y_val),batch_size = batch_size, shuffle = False), \n",
    "                                                            DataLoader(Dataset(ARM_x_test_tokenized, ARM_y_test),batch_size = batch_size, shuffle = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.442 - validation loss:      0.534                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.810 - validation accuracy:      0.726\n",
      "EPOCH 1 training f1_score:      0.786 - validation f1_score:      0.634\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.408 - validation loss:      0.546                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.825 - validation accuracy:      0.723\n",
      "EPOCH 2 training f1_score:      0.803 - validation f1_score:      0.623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.376 - validation loss:      0.557                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.844 - validation accuracy:      0.725\n",
      "EPOCH 3 training f1_score:      0.826 - validation f1_score:      0.634\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.350 - validation loss:      0.561                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.861 - validation accuracy:      0.716\n",
      "EPOCH 4 training f1_score:      0.840 - validation f1_score:      0.619\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 training loss:      0.325 - validation loss:      0.587                                                                                                                                                                                                                                                      \n",
      "EPOCH 5 training accuracy:      0.869 - validation accuracy:      0.713\n",
      "EPOCH 5 training f1_score:      0.853 - validation f1_score:      0.611\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data =   model1.train_network(train_dataloader, \n",
    "                    validation_dataloader, \n",
    "                    torch.optim.Adam, \n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    device=device, \n",
    "                    batch_size=32,\n",
    "                    verbose=True, \n",
    "                    output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                    metrics={\n",
    "                     \"accuracy\": accuracy_score, \n",
    "                     \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                    learning_rate=1e-6,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 training loss:      0.565 - validation loss:      0.659                                                                                                                                                                                                                                                      \n",
      "EPOCH 1 training accuracy:      0.730 - validation accuracy:      0.640\n",
      "EPOCH 1 training f1_score:      0.702 - validation f1_score:      0.527\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 2 training loss:      0.526 - validation loss:      0.624                                                                                                                                                                                                                                                      \n",
      "EPOCH 2 training accuracy:      0.762 - validation accuracy:      0.670\n",
      "EPOCH 2 training f1_score:      0.732 - validation f1_score:      0.559\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 3 training loss:      0.490 - validation loss:      0.622                                                                                                                                                                                                                                                      \n",
      "EPOCH 3 training accuracy:      0.784 - validation accuracy:      0.672\n",
      "EPOCH 3 training f1_score:      0.757 - validation f1_score:      0.566\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 4 training loss:      0.459 - validation loss:      0.596                                                                                                                                                                                                                                                      \n",
      "EPOCH 4 training accuracy:      0.799 - validation accuracy:      0.701\n",
      "EPOCH 4 training f1_score:      0.771 - validation f1_score:      0.600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "EPOCH 5 training loss:      0.423 - validation loss:      0.611                                                                                                                                                                                                                                                      \n",
      "EPOCH 5 training accuracy:      0.818 - validation accuracy:      0.690\n",
      "EPOCH 5 training f1_score:      0.795 - validation f1_score:      0.584\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data =   model2.train_network(train_dataloader, #rispetto a model1 sembra avere risultati simili, ma ci mette più tempo\n",
    "                    validation_dataloader, \n",
    "                    torch.optim.Adam, \n",
    "                    loss_function=nn.CrossEntropyLoss(),\n",
    "                    device=device, \n",
    "                    batch_size=32,\n",
    "                    verbose=True, \n",
    "                    output_extraction_function= lambda x: torch.max(x, -1)[1].view(-1).cpu(), \n",
    "                    metrics={\n",
    "                     \"accuracy\": accuracy_score, \n",
    "                     \"f1_score\": lambda y_true, y_pred: f1_score(y_true, y_pred, average=\"macro\")},\n",
    "                    learning_rate=1e-6,\n",
    "                    epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Premise/Conclusion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are:\n",
      "      - 662 conclusions\n",
      "      - 1857 premises\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PCR_x = []\n",
    "PCR_y = []\n",
    "all_premises = set()\n",
    "all_conclusions = set()\n",
    "all_clause = set()\n",
    "for case in refactored_dataset:\n",
    "    n_clauses = case[\"n_clauses\"]\n",
    "    clauses = case[\"all_clauses\"]\n",
    "    for argument in case[\"arguments\"]:\n",
    "        all_conclusions.add(clauses[argument[\"conclusion\"]])\n",
    "        all_clause.add(clauses[argument[\"conclusion\"]])\n",
    "        for premise in argument[\"premises\"]:\n",
    "            all_premises.add(clauses[premise])\n",
    "            all_clause.add(clauses[premise])\n",
    "\n",
    "for clause in all_clause:\n",
    "    current_y = torch.zeros(2)\n",
    "    if clause in all_premises:\n",
    "        current_y[0] = 1\n",
    "    if clause in all_conclusions:\n",
    "        current_y[1] = 1\n",
    "    PCR_x.append(clause)\n",
    "    PCR_y.append(current_y)\n",
    "print(f\"\"\"\n",
    "There are:\n",
    "      - {len([y for y in PCR_y if y[1] == 1])} conclusions\n",
    "      - {len([y for y in PCR_y if y[0] == 1])} premises\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
